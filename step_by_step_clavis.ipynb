{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Working Clavis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nProduct - URL\\tModel - URL\\tStyle - URL\\tGender - URL\\tSport - URL\\tBest for - URL\\tColour - URL\\tFeatures - URL\\tCollection - URL\\tBrand - URL\\tSize - URL\\tRise - URL\\tSustainable - URL\\tMaterial - URL\\tTeams - URL\\tKit Teams - URL\\tWinter - URL\\tOutlet - URL\\tSupport - URL\\tLength - URL\\tFit - URL\\tSurface - URL\\tTechologies - URL\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is Clavis\n",
    "## Clavis is a Keyword Expansion and Categorization Tool for Digital Marketing & URL Generation\n",
    "\n",
    "## For example if you have a keyword like \"best shoes\" and you want to expand it to \"best shoes for cycling\" and \"best shoes for running\"\n",
    "## as well as categorize whether it is \"Male\", \"Female\", \"Unisex\" or \"Kids\" you can do that with Clavis\n",
    "## Also identify whether a keyword is Generic or Branded (Generic = \"best shoes\", Branded = \"Nike shoes\")\n",
    "## also it identifies the Topic of the keyword (\"Accessories\", \"Cycling Jackets\", \"Mountain Biking Jackets\", etc..)\n",
    "## lastly it will also identify which ones should be \"Deleted\" and which ones should be \"Kept\"\n",
    "\n",
    "## The input to this system are two different CSV Files:\n",
    "\n",
    "## Input 1: Keywords.csv\n",
    "## Keywords File: This is a CSV file with the following columns: Keywords\n",
    "## Keywords File Example:\n",
    "## Keywords: Best shoes, running shoes, etc..\n",
    "\n",
    "## Input 2: Categories.csv\n",
    "## Categories File: This is a CSV with the following columns: Category, Search For, Return\n",
    "## Categories File Example:\n",
    "## Category | Search For | Return\n",
    "## Gender | | Unisex --> If Search For is empty, return Unisex\n",
    "## Gender | man | Men\n",
    "## Gender | woman | Women\n",
    "## Gender | lady | Women\n",
    "## Gender | boy | Kids\n",
    "## Branded_generic | | Generic --> If Search For is empty, return Generic\n",
    "## Branded_generic | nike | Branded\n",
    "## Branded_generic | adidas | Branded\n",
    "## Branded_generic | puma | Branded\n",
    "## Branded_generic | reebok | Branded\n",
    "## Topic | | None --> If Search For is empty, return None\n",
    "## Topic | cleats | accessories\n",
    "## topic | vest | Gilet\n",
    "## Topic | jacket*cycling*mountain*jacket | mountain biking jackets --> asterisk is a wildcard character, it can be used to match multiple words\n",
    "\n",
    "## Output:\n",
    "## Output is a CSV file with the following columns: Keywords, Gender, Branded_Generic, Topic, Delete_Keep\n",
    "## Output Example:\n",
    "## Keywords | Gender | Branded_Generic | Topic | Delete_Keep\n",
    "## Best shoes | Unisex | Generic | None | Keep\n",
    "## Best shoes for cycling | Unisex | Generic | cycling | Keep\n",
    "## Best shoes for running | Unisex | Generic | running | Keep\n",
    "## Nike shoes | Unisex | Branded | None | Keep\n",
    "## Nike shoes for cycling | Unisex | Branded | cycling | Keep\n",
    "## Nike shoes for running | Unisex | Branded | running | Keep\n",
    "## Adidas shoes | Unisex | Branded | None | Keep\n",
    "## women's cycling suit | Women | Generic | cycling | Keep\n",
    "\n",
    "\n",
    "## PART 3: URL Generation\n",
    "\"\"\"\n",
    "\n",
    "Product - URL\tModel - URL\tStyle - URL\tGender - URL\tSport - URL\tBest for - URL\tColour - URL\tFeatures - URL\tCollection - URL\tBrand - URL\tSize - URL\tRise - URL\tSustainable - URL\tMaterial - URL\tTeams - URL\tKit Teams - URL\tWinter - URL\tOutlet - URL\tSupport - URL\tLength - URL\tFit - URL\tSurface - URL\tTechologies - URL\n",
    "\"\"\"\n",
    "## those are all the mappings that are available for the URL Generation\n",
    "## the matching will be done for each of the categories and then concatenated with a custom separator (default is \"-\")\n",
    "\n",
    "## There are two parts to this:\n",
    "## Part 1. Keyword Search Volume & Expansion This is done with the custom scripts we have under KeywordSearchVolume module [DONE]\n",
    "## Part 2. Keyword Categorization This is done in the aforementioned fashion from the two CSV Files [DONE]\n",
    "## Part 3. URL Generation - This is done with an extra mapping file that maps the keywords to the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reload \n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing the libraries\n",
    "import os\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## custom modules\n",
    "from KeywordSearchVolume.search_volume_extractor import run_search_volume\n",
    "from clavis_helpers import (\n",
    "    does_file_exist,\n",
    "    load_excel_and_clean,\n",
    "    get_payload,\n",
    "    clean_categories_df,\n",
    "    categorize_keywords,\n",
    "    clean_dataframe_for_categorization,\n",
    "    apply_clean_dataframe_for_categorization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"./sample_data\"\n",
    "\n",
    "## Part 1. Keyword Search Volume & Expansion\n",
    "LANGUAGE = \"English\"  ## this has to be a streamlit input\n",
    "EXPAND_KEYWORDS = True  ## this has to be a streamlit radio button\n",
    "GEOLOCATION = \"United States\"  ## this has to be a streamlit input\n",
    "\n",
    "## CLAVIS CONFI FILES\n",
    "CLAVIS_CONFIG_NAME = \"Keyword-Categorization-Mapping-Config.xlsx\"\n",
    "CLAVIS_CONFIG_SHEET_NAME = \"Config - Categorisation\"\n",
    "CLAVIS_CONFIG_FILE_PATH = os.path.join(SAVE_DIR, CLAVIS_CONFIG_NAME)\n",
    "\n",
    "## KEYWORDS AND CATEGORY FILES\n",
    "KEYWORDS_FILE_NAME = \"Keywords.csv\"\n",
    "KEYWORDS_FILE_PATH = os.path.join(SAVE_DIR, KEYWORDS_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 0. Load the files\n",
    "catz = pd.read_csv(\n",
    "    f\"{SAVE_DIR}/categories.csv\", sep=\";\"\n",
    ")\n",
    "KEYWORDS_FILE = pd.read_csv(KEYWORDS_FILE_PATH)\n",
    "\n",
    "## get the payload\n",
    "PAYLOAD = get_payload(KEYWORDS_FILE, LANGUAGE, EXPAND_KEYWORDS, GEOLOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the results from the search volume extractor\n",
    "## check if the intermediate file exits to save time\n",
    "if does_file_exist(f\"{SAVE_DIR}/intermediate_results.csv\"):\n",
    "    results_df = pd.read_csv(f\"{SAVE_DIR}/intermediate_results.csv\")\n",
    "else:\n",
    "    results = run_search_volume(**PAYLOAD)\n",
    "    ## parse the results as it is a dictionary, and we need to label those keywords which are \"ideas\" and were not in the original list\n",
    "    ## we will label them as \"idea\" and \"not idea\" respectively\n",
    "    results_df = (\n",
    "        pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"search_volume\"])\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"keywords\"})\n",
    "    )\n",
    "\n",
    "    ## add a column to the dataframe to label the keywords as \"idea\" or \"not idea\"\n",
    "    results_df[\"idea\"] = np.where(\n",
    "        results_df[\"keywords\"].isin(PAYLOAD[\"keywords\"]), \"Expanded\", \"Original\"\n",
    "    )\n",
    "\n",
    "    ## expansion factor - is the number of keywords that were generated by the search volume extractor\n",
    "    ## divided by the number of keywords that were in the original list\n",
    "    expansion_factor = len(results_df) / len(PAYLOAD[\"keywords\"])\n",
    "    print(f\"The expansion factor is {expansion_factor:.2f}x\")\n",
    "\n",
    "## save the intermediate file to avoid re-running the above code\n",
    "if does_file_exist(f\"{SAVE_DIR}/intermediate_results.csv\"):\n",
    "    pass\n",
    "else:\n",
    "    results_df.to_csv(f\"{SAVE_DIR}/intermediate_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the clavis config file \n",
    "clavis_config = load_excel_and_clean(CLAVIS_CONFIG_FILE_PATH, CLAVIS_CONFIG_SHEET_NAME)\n",
    "\n",
    "## function to perform the above steps\n",
    "separated_categories_dict = clean_categories_df(clavis_config)\n",
    "\n",
    "## cleaned dataframe \n",
    "cleaned_categories_df = apply_clean_dataframe_for_categorization(separated_categories_dict)\n",
    "\n",
    "## separate the URL generation from the categorization\n",
    "url_generation_df = cleaned_categories_df[cleaned_categories_df['Category'].str.contains('URL')]\n",
    "\n",
    "## separate the categorization from the URL generation\n",
    "categorization_df = cleaned_categories_df[~cleaned_categories_df['Category'].str.contains('URL')]\n",
    "\n",
    "categorized_keywords = categorize_keywords(results_df, categorization_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('Clavis-GswOuXK2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8091dbd070472be2363e6046d953fa5841dfc81f86941db68117ba11a41bd54e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
